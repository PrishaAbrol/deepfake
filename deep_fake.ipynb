{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrishaAbrol/deepfake/blob/main/deep_fake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install -U -q evaluate transformers datasets accelerate torch torchvision\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access the Hack folder\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "\n",
        "# Define paths to the Hack directory and subfolders\n",
        "base_dir = '/content/drive/MyDrive/Hack'\n",
        "train_dir = os.path.join(base_dir, 'Train')\n",
        "test_dir = os.path.join(base_dir, 'Test')\n",
        "val_dir = os.path.join(base_dir, 'Validation')\n",
        "\n",
        "# Function to load images and labels from a directory\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    if not os.path.exists(folder):\n",
        "        raise FileNotFoundError(f\"Error: Directory '{folder}' not found.\")\n",
        "\n",
        "    if not os.path.isdir(folder):\n",
        "        raise NotADirectoryError(f\"Error: '{folder}' is not a directory.\")\n",
        "\n",
        "    for class_folder in os.listdir(folder):\n",
        "        class_path = os.path.join(folder, class_folder)\n",
        "\n",
        "        if os.path.isdir(class_path):\n",
        "            for img_file in os.listdir(class_path):\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                try:\n",
        "                    img = Image.open(img_path).resize((224, 224))  # Resize images to 224x224\n",
        "                    img_array = np.array(img) / 255.0  # Normalize to [0, 1]\n",
        "                    images.append(img_array)\n",
        "                    labels.append(class_folder)  # Use folder name as the label\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image {img_path}: {e}\")\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load images and labels from the Train, Test, and Validation directories\n",
        "try:\n",
        "    train_images, train_labels = load_images_from_folder(train_dir)\n",
        "    test_images, test_labels = load_images_from_folder(test_dir)\n",
        "    val_images, val_labels = load_images_from_folder(val_dir)\n",
        "\n",
        "    print(\"Train set:\", train_images.shape, train_labels.shape)\n",
        "    print(\"Test set:\", test_images.shape, test_labels.shape)\n",
        "    print(\"Validation set:\", val_images.shape, val_labels.shape)\n",
        "\n",
        "except FileNotFoundError as fnf_error:\n",
        "    print(fnf_error)\n",
        "except NotADirectoryError as nd_error:\n",
        "    print(nd_error)\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Display a few images with their labels from the training set\n",
        "for i in range(5):  # Show 5 images\n",
        "    plt.imshow(train_images[i])\n",
        "    plt.title(f\"Label: {train_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Importing additional modules for machine learning\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Handle class imbalance using RandomOverSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from pathlib import Path\n",
        "\n",
        "file_names = []\n",
        "labels = []\n",
        "for file in sorted((Path(train_dir).glob('*/*.*'))):\n",
        "    label = str(file).split('/')[-2]\n",
        "    labels.append(label)\n",
        "    file_names.append(str(file))\n",
        "\n",
        "df = pd.DataFrame.from_dict({\"image\": file_names, \"label\": labels})\n",
        "print(df['label'].unique())  # Check unique labels\n",
        "\n",
        "# Resample to address class imbalance\n",
        "y = df['label'].to_numpy()\n",
        "df = df.drop(['label'], axis=1)\n",
        "ros = RandomOverSampler(random_state=83)\n",
        "df_resampled, y_resampled = ros.fit_resample(df, y)\n",
        "df_resampled['label'] = y_resampled\n",
        "\n",
        "# Convert to HuggingFace Dataset format\n",
        "from datasets import Dataset, Image\n",
        "dataset = Dataset.from_pandas(df_resampled).cast_column(\"image\", Image())\n",
        "\n",
        "# Set class labels\n",
        "labels_list = ['Real', 'Fake']\n",
        "label2id = {label: i for i, label in enumerate(labels_list)}\n",
        "id2label = {i: label for i, label in enumerate(labels_list)}\n",
        "\n",
        "# Data transformations using Torchvision\n",
        "from torchvision.transforms import Compose, Resize, RandomRotation, RandomAdjustSharpness, ToTensor, Normalize\n",
        "from transformers import ViTImageProcessor\n",
        "\n",
        "model_str = \"dima806/deepfake_vs_real_image_detection\"\n",
        "processor = ViTImageProcessor.from_pretrained(model_str)\n",
        "image_mean, image_std = processor.image_mean, processor.image_std\n",
        "size = processor.size[\"height\"]\n",
        "\n",
        "normalize = Normalize(mean=image_mean, std=image_std)\n",
        "_train_transforms = Compose([Resize((size, size)), RandomRotation(90), RandomAdjustSharpness(2), ToTensor(), normalize])\n",
        "_val_transforms = Compose([Resize((size, size)), ToTensor(), normalize])\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "dataset = dataset.train_test_split(test_size=0.2)\n",
        "train_data = dataset['train']\n",
        "test_data = dataset['test']\n",
        "\n",
        "# Apply data transformations\n",
        "train_data.set_transform(lambda examples: {'pixel_values': [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]})\n",
        "test_data.set_transform(lambda examples: {'pixel_values': [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]})\n",
        "\n",
        "# Define and configure the ViT model for classification\n",
        "from transformers import ViTForImageClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(model_str, num_labels=len(labels_list))\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "\n",
        "# Set up training arguments\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"deepfake_vs_real_image_detection\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=1e-6,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.02,\n",
        "    save_strategy='epoch',\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# Define Trainer object\n",
        "import torch\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data,\n",
        "    data_collator=lambda examples: {\n",
        "        'pixel_values': torch.stack([example[\"pixel_values\"] for example in examples]),\n",
        "        'labels': torch.tensor([example['label'] for example in examples])\n",
        "    },\n",
        "    compute_metrics=lambda eval_pred: {\n",
        "        \"accuracy\": accuracy_score(eval_pred.label_ids, eval_pred.predictions.argmax(1))\n",
        "    }\n",
        ")\n",
        "\n",
        "# Train and evaluate the model\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "\n",
        "# Confusion matrix plot function\n",
        "y_true = trainer.predict(test_data).label_ids\n",
        "y_pred = trainer.predict(test_data).predictions.argmax(1)\n",
        "\n",
        "def plot_confusion_matrix(cm, classes, title='Confusion Matrix'):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    plt.xticks(np.arange(len(classes)), classes, rotation=45)\n",
        "    plt.yticks(np.arange(len(classes)), classes)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plot_confusion_matrix(cm, classes=labels_list)\n"
      ],
      "metadata": {
        "id": "pghCaPJfrxpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print\"Here's a chatbot for extra info:\"\n",
        "import dialogflow_v2 as dialogflow\n",
        "import os\n",
        "\n",
        "# Set the path to your Google Cloud service account key file\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path-to-your-service-account-file.json\"\n",
        "\n",
        "def detect_intent_texts(project_id, session_id, text, language_code):\n",
        "    session_client = dialogflow.SessionsClient()\n",
        "    session = session_client.session_path(project_id, session_id)\n",
        "\n",
        "    text_input = dialogflow.types.TextInput(text=text, language_code=language_code)\n",
        "    query_input = dialogflow.types.QueryInput(text=text_input)\n",
        "\n",
        "    response = session_client.detect_intent(session=session, query_input=query_input)\n",
        "\n",
        "    return response.query_result.fulfillment_text\n",
        "\n",
        "# Example usage\n",
        "project_id = 'your-dialogflow-project-id'\n",
        "session_id = '123456'  # Random unique ID for each session\n",
        "text = 'Hello, how can you help me?'\n",
        "language_code = 'en'\n",
        "\n",
        "response = detect_intent_texts(project_id, session_id, text, language_code)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "e0DYCurUx7o7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEbyg1sxdGZihEL71H99zN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}